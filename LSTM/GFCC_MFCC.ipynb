{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pWUKET_MZY82"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "wJ9halu8Zg94",
    "outputId": "27933805-e96d-4940-edcc-fc131703e3f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "uwVeLb_xZha9",
    "outputId": "3413ce43-d66a-4345-896e-5dccc3c883a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting essentia\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/dc/cac5d1fa53146f7efac3b35655b33cb002b905fd5d1c700c651d1726b140/essentia-2.1b5-cp36-cp36m-manylinux1_x86_64.whl (11.1MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1MB 214kB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from essentia) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from essentia) (1.17.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from essentia) (3.13)\n",
      "Installing collected packages: essentia\n",
      "Successfully installed essentia-2.1b5\n",
      "Collecting python_speech_features\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
      "Building wheels for collected packages: python-speech-features\n",
      "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5889 sha256=765ef2e089701c21da19f23ca21f90121b33e4b86176abc64b73c494d136155c\n",
      "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
      "Successfully built python-speech-features\n",
      "Installing collected packages: python-speech-features\n",
      "Successfully installed python-speech-features-0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install essentia\n",
    "!pip install python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/drive/My\\ Drive/data/o.zip\n",
    "!unzip /content/drive/My\\ Drive/data/other.zip\n",
    "!unzip /content/drive/My\\ Drive/data/w1.zip\n",
    "!unzip /content/drive/My\\ Drive/data/wheeze2.zip\n",
    "!unzip /content/drive/My\\ Drive/data/wheeze_and_crackle.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CeARNicZZwsE",
    "outputId": "7011f315-5dfe-4a11-dacc-46e8aceab42c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from shutil import copyfile\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as signal\n",
    "from scipy import stats\n",
    "import python_speech_features\n",
    "from essentia.standard import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ThSzwvBBZyjl"
   },
   "outputs": [],
   "source": [
    "w = Windowing(type = 'hann')\n",
    "spectrum = Spectrum()\n",
    "mfcc = MFCC(highFrequencyBound = 8000, sampleRate = 16000)\n",
    "gfcc = GFCC(highFrequencyBound = 8000, numberCoefficients = 40, sampleRate = 16000)\n",
    "def get_feature(data):\n",
    "  mfccs = []\n",
    "  gfccs = []\n",
    "  for frame in FrameGenerator(data, frameSize=1024, hopSize=512, startFromZero=True):\n",
    "    mfcc_bands, mfcc_coeffs = mfcc(spectrum(w(frame)))\n",
    "    gfcc_bands, gfcc_coeffs = gfcc(spectrum(w(frame)))\n",
    "    mfccs.append(mfcc_coeffs)\n",
    "    gfccs.append(gfcc_coeffs)\n",
    "  test = np.asarray(gfccs)\n",
    "  tam = np.asarray(mfccs)\n",
    "  tam1 = python_speech_features.base.delta(tam, 10)\n",
    "  tam2 = python_speech_features.base.delta(tam1, 10)\n",
    "  return np.concatenate((test, tam, tam1, tam2), axis = 1)\n",
    "def get_feature_all(dirs, X, Y, idx):\n",
    "  for i in range(len(dirs)):\n",
    "    dir = dirs[i] + \"/\"\n",
    "    for filename in os.listdir(dir):\n",
    "      try:\n",
    "        rate, data = wav.read(dir + filename)\n",
    "        test = [0]\n",
    "        test[0] = idx[i]\n",
    "        if idx[i] == 0:\n",
    "          for t in range(0, 20):\n",
    "            X.append(get_feature(np.roll(data, t * len(data)//20)))\n",
    "            Y.append(test)\n",
    "        elif idx[i] == 1:\n",
    "          for t in range(0, 4):\n",
    "            X.append(get_feature(np.roll(data, t * len(data)//4)))\n",
    "            Y.append(test)\n",
    "      except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0AcnBIEeZ77r"
   },
   "outputs": [],
   "source": [
    "dirs = [\"/content/wheeze2/wheeze\", \"/content/other\", \"/content/w\", \"/content/wheeze_and_crackle\", \"/content/o\"]\n",
    "labels = [0, 1, 0, 0, 1]\n",
    "X = []\n",
    "y = []\n",
    "get_feature_all(dirs,X, y, labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_2E7uRLZ95y"
   },
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "X1 = X\n",
    "X = stats.zscore(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nf3SxFOYaTMc"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(64, return_sequences=True, input_shape=(93, 79)))\n",
    "  model.add(LSTM(64))\n",
    "  model.add(Dense(1, activation = \"sigmoid\"))\n",
    "  model.compile(loss='binary_crossentropy', optimizer= \"adam\", metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vl15S_T3acxm"
   },
   "outputs": [],
   "source": [
    "def train(X_aug, y_aug, epochs = 40):\n",
    "  i = 1\n",
    "  for train_index, test_index in kf.split(X_aug):\n",
    "    print(\"Cross Valid: \" + str(i))\n",
    "    model = create_model()\n",
    "    model.fit(X_aug[train_index], y_aug[train_index], epochs = epochs, batch_size = 64)\n",
    "    y_pred = model.predict(X_aug[test_index])\n",
    "    y_pred = [1 * (x[0]>=0.5) for x in y_pred]\n",
    "    print(confusion_matrix(y_aug[test_index], y_pred))\n",
    "    gc.collect()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use same randomstate 28\n",
    "kf = KFold(n_splits=5, shuffle= True, random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4V8mXWGFmwyK",
    "outputId": "26713e86-a618-4fd3-fb8c-e27e9809a018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Valid: 1\n",
      "Epoch 1/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 0.2799 - acc: 0.8893\n",
      "Epoch 2/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0852 - acc: 0.9706\n",
      "Epoch 3/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0371 - acc: 0.9887\n",
      "Epoch 4/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0245 - acc: 0.9927\n",
      "Epoch 5/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0223 - acc: 0.9930\n",
      "Epoch 6/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0137 - acc: 0.9957\n",
      "Epoch 7/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0146 - acc: 0.9956\n",
      "Epoch 8/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0127 - acc: 0.9964\n",
      "Epoch 9/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0053 - acc: 0.9987\n",
      "Epoch 10/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0103 - acc: 0.9969\n",
      "Epoch 11/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0057 - acc: 0.9983\n",
      "Epoch 12/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0137 - acc: 0.9962\n",
      "Epoch 13/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0053 - acc: 0.9984\n",
      "Epoch 14/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0044 - acc: 0.9985\n",
      "Epoch 15/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0060 - acc: 0.9985\n",
      "Epoch 16/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 0.0056 - acc: 0.9983\n",
      "Epoch 17/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 18/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0160 - acc: 0.9951\n",
      "Epoch 19/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0110 - acc: 0.9970\n",
      "Epoch 20/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0113 - acc: 0.9968\n",
      "Epoch 21/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 0.0049 - acc: 0.9986\n",
      "Epoch 22/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0032 - acc: 0.9990\n",
      "Epoch 23/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 2.5227e-04 - acc: 0.9999\n",
      "Epoch 24/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 6.4938e-05 - acc: 1.0000\n",
      "Epoch 25/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 3.9848e-05 - acc: 1.0000\n",
      "Epoch 26/35\n",
      "24739/24739 [==============================] - 81s 3ms/step - loss: 2.7634e-05 - acc: 1.0000\n",
      "Epoch 27/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 2.0339e-05 - acc: 1.0000\n",
      "Epoch 28/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 1.5465e-05 - acc: 1.0000\n",
      "Epoch 29/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 1.1935e-05 - acc: 1.0000\n",
      "Epoch 30/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 9.3115e-06 - acc: 1.0000\n",
      "Epoch 31/35\n",
      "24739/24739 [==============================] - 81s 3ms/step - loss: 7.2776e-06 - acc: 1.0000\n",
      "Epoch 32/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 5.7324e-06 - acc: 1.0000\n",
      "Epoch 33/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 4.5456e-06 - acc: 1.0000\n",
      "Epoch 34/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 3.6537e-06 - acc: 1.0000\n",
      "Epoch 35/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 2.9493e-06 - acc: 1.0000\n",
      "[[3030    7]\n",
      " [   2 3146]]\n",
      "Cross Valid: 2\n",
      "Epoch 1/35\n",
      "24739/24739 [==============================] - 82s 3ms/step - loss: 0.2765 - acc: 0.8877\n",
      "Epoch 2/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0808 - acc: 0.9720\n",
      "Epoch 3/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0460 - acc: 0.9857\n",
      "Epoch 4/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0376 - acc: 0.9887\n",
      "Epoch 5/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0230 - acc: 0.9928\n",
      "Epoch 6/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0161 - acc: 0.9957\n",
      "Epoch 7/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0123 - acc: 0.9966\n",
      "Epoch 8/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0157 - acc: 0.9952\n",
      "Epoch 9/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0100 - acc: 0.9969\n",
      "Epoch 10/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0083 - acc: 0.9974\n",
      "Epoch 11/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 0.0052 - acc: 0.9983\n",
      "Epoch 12/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0123 - acc: 0.9963\n",
      "Epoch 13/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0196 - acc: 0.9949\n",
      "Epoch 14/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 15/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0026 - acc: 0.9991\n",
      "Epoch 16/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0116 - acc: 0.9965\n",
      "Epoch 17/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0072 - acc: 0.9982\n",
      "Epoch 18/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0040 - acc: 0.9989\n",
      "Epoch 19/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 20/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 7.4554e-04 - acc: 0.9999\n",
      "Epoch 21/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 6.3015e-05 - acc: 1.0000\n",
      "Epoch 22/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 3.5596e-05 - acc: 1.0000\n",
      "Epoch 23/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 2.3976e-05 - acc: 1.0000\n",
      "Epoch 24/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 1.7144e-05 - acc: 1.0000\n",
      "Epoch 25/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 1.2740e-05 - acc: 1.0000\n",
      "Epoch 26/35\n",
      "24739/24739 [==============================] - 81s 3ms/step - loss: 9.6612e-06 - acc: 1.0000\n",
      "Epoch 27/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 7.4241e-06 - acc: 1.0000\n",
      "Epoch 28/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 5.8121e-06 - acc: 1.0000\n",
      "Epoch 29/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 4.5892e-06 - acc: 1.0000\n",
      "Epoch 30/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 3.6549e-06 - acc: 1.0000\n",
      "Epoch 31/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 2.9203e-06 - acc: 1.0000\n",
      "Epoch 32/35\n",
      "24739/24739 [==============================] - 83s 3ms/step - loss: 2.3432e-06 - acc: 1.0000\n",
      "Epoch 33/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 1.8769e-06 - acc: 1.0000\n",
      "Epoch 34/35\n",
      "24739/24739 [==============================] - 83s 3ms/step - loss: 1.5171e-06 - acc: 1.0000\n",
      "Epoch 35/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 1.2309e-06 - acc: 1.0000\n",
      "[[3074    1]\n",
      " [   5 3105]]\n",
      "Cross Valid: 3\n",
      "Epoch 1/35\n",
      "24739/24739 [==============================] - 82s 3ms/step - loss: 0.2656 - acc: 0.8911\n",
      "Epoch 2/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0938 - acc: 0.9700\n",
      "Epoch 3/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0397 - acc: 0.9870\n",
      "Epoch 4/35\n",
      "24739/24739 [==============================] - 83s 3ms/step - loss: 0.0306 - acc: 0.9906\n",
      "Epoch 5/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0212 - acc: 0.9930\n",
      "Epoch 6/35\n",
      "24739/24739 [==============================] - 84s 3ms/step - loss: 0.0137 - acc: 0.9956\n",
      "Epoch 7/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0233 - acc: 0.9937\n",
      "Epoch 8/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0149 - acc: 0.9953\n",
      "Epoch 9/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 0.0106 - acc: 0.9970\n",
      "Epoch 10/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0058 - acc: 0.9986\n",
      "Epoch 11/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0032 - acc: 0.9994\n",
      "Epoch 12/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0120 - acc: 0.9965\n",
      "Epoch 13/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0069 - acc: 0.9982\n",
      "Epoch 14/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0083 - acc: 0.9977\n",
      "Epoch 15/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0195 - acc: 0.9951\n",
      "Epoch 16/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0056 - acc: 0.9986\n",
      "Epoch 17/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0163 - acc: 0.9950\n",
      "Epoch 18/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0057 - acc: 0.9985\n",
      "Epoch 19/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 6.3254e-04 - acc: 0.9999\n",
      "Epoch 20/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 1.2770e-04 - acc: 1.0000\n",
      "Epoch 21/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 7.2737e-05 - acc: 1.0000\n",
      "Epoch 22/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 4.6219e-05 - acc: 1.0000\n",
      "Epoch 23/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 3.2702e-05 - acc: 1.0000\n",
      "Epoch 24/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 2.4384e-05 - acc: 1.0000\n",
      "Epoch 25/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 1.8474e-05 - acc: 1.0000\n",
      "Epoch 26/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 1.4246e-05 - acc: 1.0000\n",
      "Epoch 27/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 1.1012e-05 - acc: 1.0000\n",
      "Epoch 28/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 8.6703e-06 - acc: 1.0000\n",
      "Epoch 29/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 6.6611e-06 - acc: 1.0000\n",
      "Epoch 30/35\n",
      "24739/24739 [==============================] - 81s 3ms/step - loss: 5.2860e-06 - acc: 1.0000\n",
      "Epoch 31/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 4.2146e-06 - acc: 1.0000\n",
      "Epoch 32/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 3.3435e-06 - acc: 1.0000\n",
      "Epoch 33/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 2.6706e-06 - acc: 1.0000\n",
      "Epoch 34/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 2.1433e-06 - acc: 1.0000\n",
      "Epoch 35/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 1.7223e-06 - acc: 1.0000\n",
      "[[3135    3]\n",
      " [   5 3042]]\n",
      "Cross Valid: 4\n",
      "Epoch 1/35\n",
      "24739/24739 [==============================] - 82s 3ms/step - loss: 0.2960 - acc: 0.8798\n",
      "Epoch 2/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.1120 - acc: 0.9613\n",
      "Epoch 3/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0736 - acc: 0.9744\n",
      "Epoch 4/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0444 - acc: 0.9836\n",
      "Epoch 5/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0408 - acc: 0.9869\n",
      "Epoch 6/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0196 - acc: 0.9941\n",
      "Epoch 7/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0215 - acc: 0.9937\n",
      "Epoch 8/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0073 - acc: 0.9980\n",
      "Epoch 9/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0090 - acc: 0.9972\n",
      "Epoch 10/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0190 - acc: 0.9943\n",
      "Epoch 11/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0100 - acc: 0.9973\n",
      "Epoch 12/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0096 - acc: 0.9975\n",
      "Epoch 13/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0021 - acc: 0.9994\n",
      "Epoch 14/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0106 - acc: 0.9970\n",
      "Epoch 15/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0208 - acc: 0.9947\n",
      "Epoch 16/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0089 - acc: 0.9977\n",
      "Epoch 17/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 18/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0045 - acc: 0.9988\n",
      "Epoch 19/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0210 - acc: 0.9938\n",
      "Epoch 20/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0121 - acc: 0.9965\n",
      "Epoch 21/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0101 - acc: 0.9968\n",
      "Epoch 22/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 0.0036 - acc: 0.9989\n",
      "Epoch 23/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0052 - acc: 0.9983\n",
      "Epoch 24/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 25/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 4.7305e-04 - acc: 0.9999\n",
      "Epoch 26/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 9.0183e-05 - acc: 1.0000\n",
      "Epoch 27/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 3.7992e-05 - acc: 1.0000\n",
      "Epoch 28/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 2.5364e-05 - acc: 1.0000\n",
      "Epoch 29/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 1.8510e-05 - acc: 1.0000\n",
      "Epoch 30/35\n",
      "24739/24739 [==============================] - 79s 3ms/step - loss: 1.4036e-05 - acc: 1.0000\n",
      "Epoch 31/35\n",
      "24739/24739 [==============================] - 78s 3ms/step - loss: 1.0916e-05 - acc: 1.0000\n",
      "Epoch 32/35\n",
      "24739/24739 [==============================] - 80s 3ms/step - loss: 8.5981e-06 - acc: 1.0000\n",
      "Epoch 33/35\n",
      "17216/24739 [===================>..........] - ETA: 23s - loss: 7.2217e-06 - acc: 1.0000Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "train(X, y, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-mEK-TRnPY1"
   },
   "outputs": [],
   "source": [
    "def train(X_aug, y_aug, epochs = 40):\n",
    "  i = 1\n",
    "  for train_index, test_index in kf.split(X_aug):\n",
    "    if i < 4:\n",
    "      i += 1\n",
    "      continue\n",
    "    print(\"Cross Valid: \" + str(i))\n",
    "    model = create_model()\n",
    "    model.fit(X_aug[train_index], y_aug[train_index], epochs = epochs, batch_size = 64, verbose = 0)\n",
    "    y_pred = model.predict(X_aug[test_index])\n",
    "    y_pred = [1 * (x[0]>=0.5) for x in y_pred]\n",
    "    print(confusion_matrix(y_aug[test_index], y_pred))\n",
    "    gc.collect()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "id": "ZDFguUDe4_vA",
    "outputId": "1187d555-b924-4e5e-e6a2-68265777e00f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Valid: 4\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "[[3138    2]\n",
      " [   3 3042]]\n",
      "Cross Valid: 5\n",
      "[[3046    4]\n",
      " [   4 3130]]\n"
     ]
    }
   ],
   "source": [
    "train(X, y, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SfWuHvaq5BQy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Untitled17.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
